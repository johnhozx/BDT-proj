version: '2.1'
services:

# Apache kafka
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    networks:
      - cluster_network

#kafka:
  kafka:
    image: wurstmeister/kafka
    container_name: kafka
    # hostname: kafka-docker
    ports:
      - "9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 172.17.0.1
      KAFKA_ADVERTISED_PORT_NAME: 9092
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - cluster_network


#Spark-master
  spark:
    image: docker.io/bitnami/spark:3.4
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - "20:2222"
      - "6066:6066"
      - "7070:7070"
      - "8080:8080"
      - "50070:50070"
    networks:
      - cluster_network
   # command: start-spark master
    
#Sparkwoker 
  spark-worker:
    image: docker.io/bitnami/spark:3.4
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    networks:
      - cluster_network
    #command: start-spark master      

# Apache Hbase
  Hbase:
    image: yehex42241/hbase:v1
    container_name: hbase
    hostname: hbase-docker
    ports:
      - "8081:8080"
      - "2182:2182"
      - "8085:8085"
      - "9090:9090"
      - "9095:9095"
      - "16010:16010"
    networks:
      - cluster_network   
    command: ["tail", "-f", "/dev/null"]    

networks:
  cluster_network:
    name: kafka-spark-hbase
